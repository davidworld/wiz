From: WizMime<support@wiz.cn>
Subject: =?gb2312?B?c3BhcmsgMi5YINLJxNHOysziu+PX3A==?=
Date: Date: Fri, 23 Jul 2021 05:54:41 +0800
MIME-Version: 1.0
Content-Type: multipart/related;
	type="multipart/alternative";
	boundary="----=_Next_Part_0001284654.531"

This is a multi-part message in MIME format.

------=_Next_Part_0001284654.531
Content-Type: multipart/alternative;
	boundary="----=_Next_Part_0000428218.495"


------=_Next_Part_0000428218.495
Content-Type: text/plain;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable

This is a multi-part message in MIME format.

------=_Next_Part_0000428218.495
Content-Type: text/html;
	charset="gb2312"
Content-Transfer-Encoding: quoted-printable

<!DOCTYPE HTML><html><head>=0D=0A<meta http-equiv=3D"Content-Type=
" content=3D"text/html; charset=3Dgb2312">=0A=0A=0A=0A=0A=0A<titl=
e>spark 2.X =D2=C9=C4=D1=CE=CA=CC=E2=BB=E3=D7=DC</title>=0A    =0A=
<style id=3D"wiz_custom_css">html, .wiz-editor-body {font-size: 1=
2pt;}.wiz-editor-body {font-family: Helvetica, 'Hiragino Sans GB'=
, '=E5=BE=AE=E8=BD=AF=E9=9B=85=E9=BB=91', 'Microsoft YaHei UI', S=
imSun, SimHei, arial, sans-serif;line-height: 1.7;margin: 0 auto;=
padding: 20px 16px;padding: 1.25rem 1rem;}.wiz-editor-body h1,.wi=
z-editor-body h2,.wiz-editor-body h3,.wiz-editor-body h4,.wiz-edi=
tor-body h5,.wiz-editor-body h6 {margin:20px 0 10px;margin:1.25re=
m 0 0.625rem;padding: 0;font-weight: bold;}.wiz-editor-body h1 {f=
ont-size:20pt;font-size:1.67rem;}.wiz-editor-body h2 {font-size:1=
8pt;font-size:1.5rem;}.wiz-editor-body h3 {font-size:15pt;font-si=
ze:1.25rem;}.wiz-editor-body h4 {font-size:14pt;font-size:1.17rem=
;}.wiz-editor-body h5 {font-size:12pt;font-size:1rem;}.wiz-editor=
-body h6 {font-size:12pt;font-size:1rem;color: #777777;margin: 1r=
em 0;}.wiz-editor-body div,.wiz-editor-body p,.wiz-editor-body ul=
,.wiz-editor-body ol,.wiz-editor-body dl,.wiz-editor-body li {mar=
gin:8px 0;}.wiz-editor-body blockquote,.wiz-editor-body table,.wi=
z-editor-body pre,.wiz-editor-body code {margin:8px 0;}.wiz-edito=
r-body .CodeMirror pre {margin:0;}.wiz-editor-body ul,.wiz-editor=
-body ol {padding-left:32px;padding-left:2rem;}.wiz-editor-body o=
l.wiz-list-level1 > li {list-style-type:decimal;}.wiz-editor-body=
 ol.wiz-list-level2 > li {list-style-type:lower-latin;}.wiz-edito=
r-body ol.wiz-list-level3 > li {list-style-type:lower-roman;}.wiz=
-editor-body blockquote {padding: 0 12px;}.wiz-editor-body blockq=
uote > :first-child {margin-top:0;}.wiz-editor-body blockquote >=20=
:last-child {margin-bottom:0;}.wiz-editor-body img {border:0;max-=
width:100%;height:auto !important;margin:2px 0;}.wiz-editor-body=20=
table {border-collapse:collapse;border:1px solid #bbbbbb;}.wiz-ed=
itor-body td,.wiz-editor-body th {padding:4px 8px;border-collapse=
:collapse;border:1px solid #bbbbbb;min-height:28px;word-break:bre=
ak-word;box-sizing: border-box;}.wiz-hide {display:none !importan=
t;}</style></head>=0A=0A<body class=3D"wiz-editor-body"  spellche=
ck=3D"false"><div>spark 2.X =D2=C9=C4=D1=CE=CA=CC=E2=BB=E3=D7=DC<=
/div><div>=D4=AD=B4=B4xwc35047 =D7=EE=BA=F3=B7=A2=B2=BC=D3=DA2016=
-12-29 23:39:18 =D4=C4=B6=C1=CA=FD 20203  =CA=D5=B2=D8</div><div>=
=D5=B9=BF=AA</div><div>=B5=B1=C7=B0spark=C8=CE=CE=F1=B6=BC=CA=C7=D4=
=CB=D0=D0=D4=DAyarn=C9=CF=A3=AC=CB=F9=D2=D4=B2=BB=D3=C3=C6=F4=B6=AF=
=B3=A4=BD=F8=B3=CCworker=A3=AC=D2=B2=C3=BB=D3=D0master=B5=C4HA=CE=
=CA=CC=E2=A3=AC=CB=F9=D2=D4=D6=F7=D2=AA=B5=C4=CE=CA=CC=E2=D4=DA=C8=
=CE=CE=F1=D6=B4=D0=D0=B2=E3=C3=E6=A1=A3</div><div><br></div><div>=
=D7=F7=D2=B5=B9=CA=D5=CF=B7=D6=C0=E0</div><div>=B9=CA=D5=CF=D6=F7=
=D2=AA=B7=D6=CE=AA=B0=E6=B1=BE=A3=AC=C4=DA=B4=E6=BA=CD=C8=A8=CF=DE=
=C8=FD=B7=BD=C3=E6=A1=A3</div><div><br></div><div>=B8=F7=D6=D6=B0=
=E6=B1=BE=B2=BB=D2=BB=D6=C2</div><div>=B8=F7=D6=D6=C4=DA=B4=E6=D2=
=E7=B3=F6</div><div>=C6=E4=CB=FB=CE=CA=CC=E2</div><div>=B0=E6=B1=BE=
=B2=BB=D2=BB=D6=C2</div><div>#####1=A3=A9java=B0=E6=B1=BE=B2=BB=D2=
=BB=D6=C2</div><div>=B1=A8=B4=ED=A3=BAjava.lang.UnsupportedClassV=
ersionError: com/immomo/recommend/RedisDao: Unsupported major.min=
or version 52.0</div><div>=B4=A6=C0=ED=A3=BA=B8=C3=CE=CA=CC=E2=D2=
=BB=B0=E3=CA=C7spark=B5=C4java=B0=E6=B1=BE=D3=EB=D7=F7=D2=B5=B1=E0=
=D2=EB=B5=C4java=B0=E6=B1=BE=B2=BB=D2=BB=D6=C2=A3=AC=BD=A8=D2=E9=BD=
=AB=B1=BE=B5=D8java=B0=E6=B1=BE=B8=C4=CE=AA=D3=EBspark=D2=BB=D6=C2=
=B5=C4=B0=E6=B1=BE=A3=A8=C4=BF=C7=B0=BC=AF=C8=BA=CA=C71.7.0_71=A3=
=A9=A1=A3</div><div>2=A3=A9scala=B0=E6=B1=BE=B2=BB=D2=BB=D6=C2</d=
iv><div>=B1=A8=B4=ED=A3=BA</div><div><br></div><div>java.lang.NoS=
uchMethodError: scala.reflect.api.JavaUniverse.runtimeMirror(Ljav=
a/lang/ClassLoader;)Lscala/reflect/api/</div><div>&nbsp; &nbsp; J=
avaMirrors JavaMirror;</div><div>1</div><div>2</div><div>=B4=A6=C0=
=ED=A3=BA=B8=C3=B1=A8=B4=ED=BE=CD=CA=C7=B1=BE=B5=D8=CA=B9=D3=C3=B5=
=C4scala=B0=E6=B1=BE=D3=EB=BC=AF=C8=BA=B5=C4=B2=BB=D2=BB=D6=C2=A3=
=AC=BD=A8=D2=E9=B0=D1=B1=BE=B5=D8scala=B0=E6=B1=BE=CC=E6=BB=BB=CE=
=AA=BC=AF=C8=BA=B0=E6=B1=BEscala 2.11.8</div><div>1</div><div>3=A3=
=A9 =B1=BE=B5=D8jar=B0=FC=B8=FAhdfs=D4=B6=B3=CC=B5=C4=B2=BB=D2=BB=
=D6=C2</div><div>=B1=A8=B4=ED=A3=BA</div><div>local class incompa=
tible: stream classdesc serialVersionID =3D -69655873838049584793=
74, local class serialVersionID =3D -2231952633394736947</div><di=
v><br></div><div>4=A3=A9 spark=B0=E6=B1=BE=B2=BB=D2=BB=D6=C2</div=
><div>=B1=A8=B4=ED=A3=BA</div><div>Exception in thread "main" jav=
a.lang.NoSuchMethodError: org.apache.spark.SparkContext.assertNot=
Stopped()at org.apache.spark.sql.SparkSession.&lt;init&gt;(SparkS=
ession.scala:80)</div><div>=B4=A6=C0=ED=A3=BA=BC=EC=B2=E9bash=BA=CD=
spark-env.sh=D6=D0=B5=C4SPARK_HOME=A3=AC=BF=B4=CA=C7=B2=BB=CA=C7=C4=
=BF=B1=EA=B0=E6=B1=BE=A3=AC=C8=E7=B9=FB=B2=BB=CA=C7=BE=CD=D0=DE=B8=
=C4=A1=A3=D5=E2=B8=F6=CE=CA=CC=E2=D4=DAspark=D0=C2=C0=CF=B0=E6=B1=
=BE=C7=A8=D2=C6=D6=D0=BF=C9=C4=DC=B3=F6=CF=D6=A1=A3</div><div><br=
></div><div>hive metastore=D3=EBspark=B5=C4=B1=E0=D2=EBhive=B0=E6=
=B1=BE=B2=BB=D2=BB=D6=C2=A3=A8spark sql =B2=E5=C8=EB=D3=EF=BE=E4=CA=
=A7=B0=DC=A3=A9</div><div>=B1=A8=B4=ED=A3=BA</div><div>Caused by:=
 org.apache.hadoop.hive.ql.metadata.HiveException: Unable to alte=
r table. Invalid method name: 'alter_table_with_cascade' Caused b=
y: org.apache.thrift.TApplicationException: Invalid method name:=20=
'alter_table_with_cascade'</div><div>=BD=E2=BE=F6=B7=BD=B7=A8=A3=BA=
=C8=CE=CE=F1=C6=F4=B6=AF=BC=D3=B2=CE=CA=FD --conf spark.sql.hive.=
metastore.version=3D=A1=B00.14.0=A1=B1 --conf spark.sql.hive.meta=
store.jars=3Dmaven</div><div>=D4=DAhdfs=C9=CF=B4=B4=BD=A8=CE=C4=BC=
=FE=A3=AC=B2=A2=D4=DASPARK_HOME/conf/hive-site.xml=C9=E8=D6=C3=B6=
=D4=D3=A6=B2=CE=CA=FD=A3=BAhive.exec.stagingdir=D6=B5=CE=AA/tmp/h=
ive/spark-${user.name}</div><div>=B8=C3=B2=CE=CA=FD=C8=A8=CF=DE=C9=
=E8=D6=C3=CE=AA777</div><div>=D5=E2=B8=F6maven=C9=E6=BC=B0=B0=FC=D3=
=D0~/.m2 ~/.ivy2=B5=C4jar=CE=C4=BC=FE</div><div>=B2=CE=BF=BC=A3=BA=
https://discourse.looker.com/t/fixing-spark-default-metastore-and=
-hive-metastore-mismatch-issues-prior-to-looker-3-44/2123</div><d=
iv><br></div><div>=C4=DA=B4=E6=CE=CA=CC=E2</div><div>1=A3=A9GC=BF=
=AA=CF=FA=B3=AC=B9=FD=CF=DE=D6=C6</div><div>=B1=A8=B4=ED=A3=BA</d=
iv><div>java.lang.OutOfMemoryError: GC overhead limit exceeded at=
 scala.collection.immutable.HashMap.scala.collection.immutable.Ha=
shMap makeHashTrieMap(HashMap.scala:175)</div><div>=B4=A6=C0=ED=A3=
=BA=B7=D6=CE=AA=C1=BD=B8=F6=BD=C7=B6=C8=A3=AC=D2=BB=CA=C7=CA=C7=BC=
=EC=B2=E9=B4=FA=C2=EB=A3=AC=BC=F5=C9=D9=B2=BB=B1=D8=D2=AA=B5=C4=C8=
=DF=D3=E0=A3=AC=D6=D8=D3=C3=B5=C4RDD=D2=AA=D0=F2=C1=D0=BB=AF=BB=BA=
=B4=E6=A3=AC=BC=F5=C9=D9shuffle=CA=FD=BE=DD=A3=AC=BC=D3=B4=F3=B2=A2=
=D0=D0=B6=C8=A3=BB=B6=FE=B4=D3=B2=CE=CA=FD=C5=E4=D6=C3=BF=B4=A3=AC=
=BC=D3=B4=F3executor=C4=DA=B4=E6=A3=AC=D4=F6=BC=D3shuffle buffer=BB=
=BA=B4=E6=A3=AC=B5=AB=D3=D0=CA=B1=BA=F2=D2=B2=D2=F2=CE=AAjob=D0=B4=
=B5=C4=CC=AB=B5=CD=D0=A7=B6=F8=B3=F6=CF=D6=CE=DE=D0=A7=A1=A3</div=
><div><br></div><div>2=A3=A9=BF=D5=D6=B8=D5=EB=D2=EC=B3=A3</div><=
div>=B1=A8=B4=ED=A3=BA</div><div>java.lang.NullPointerException a=
t com.immomo.recommend.recommend_molive anonfun 1.apply(recommend=
_molive.scala:83)</div><div>=B4=A6=C0=ED=A3=BA=B8=C3=CE=CA=CC=E2=D2=
=BB=B0=E3=CA=C7=B4=FA=C2=EB=D6=D0=B5=C4=A3=AC=BC=EC=B2=E9=CA=FD=D7=
=E9=A3=AC=B6=D4=CF=F3=C4=DA=C8=DD=CA=C7=B7=F1=BF=C9=C4=DC=CE=AA=BF=
=D5=A3=BB=D3=C8=C6=E4=CA=C7=B1=ED=CA=FD=BE=DD=A3=AC=C4=DC=D3=D0=D7=
=D6=B6=CE=B5=C4=D6=B5=CE=AAnull=A3=AC=B5=AB=C3=BB=D3=D0=B4=A6=C0=ED=
null=A3=AC=B3=F6=CF=D6=D5=E2=B8=F6=B4=ED=CE=F3=A1=A3</div><div><b=
r></div><div>3=A3=A9kyro =BB=BA=B4=E6=D2=E7=B3=F6</div><div>=B1=A8=
=B4=ED=A3=BA</div><div>java.lang.OutOfMemoryError: Java heap spac=
e at com.esotericsoftware.kryo.io.Output.require(Output.java:168)=
</div><div>=B4=A6=C0=ED=A3=BA=B8=C3=B1=A8=B4=ED=B6=D1=D5=BB=BF=C9=
=D2=D4=BF=B4=B5=BD=CA=C7kyro=C7=EB=C7=F3=BF=D5=BC=E4=A3=AC=BD=E1=B9=
=FB=B2=BB=B9=BB=B3=F6=CF=D6=D2=E7=B3=F6=A3=AC=D2=F2=CE=AAkyro=D0=F2=
=C1=D0=BB=AF=C6=F7=C4=DC=D0=F2=C1=D0=BB=AF=B5=C4=B5=A5=B8=F6=B6=D4=
=CF=F3=D7=EE=B4=F3=CF=DE=D6=C6=CE=AAspark.kryoserializer.buffer.m=
ax=B6=A8=D2=E5=A3=AC=D5=E2=B8=F6=D6=B5=D7=EE=B4=F3=CE=AA2g=A1=A3=CB=
=F9=D2=D4=BD=A8=D2=E9=D3=C5=CF=C8=BC=EC=B2=E9=B4=FA=C2=EB=D6=D0=B5=
=C4=B4=F3=B6=D4=CF=F3=A3=AC=CF=EB=B0=EC=B7=A8=B2=C3=BC=F4=B6=D4=CF=
=F3=B4=F3=D0=A1=A3=AC=C8=E7=B9=FB=B2=BB=D0=D0=D4=D9=BF=BC=C2=C7=D4=
=F6=B4=F3spark.kryoserializer.buffer.max=CA=FD=D6=B5=A1=A3</div><=
div><br></div><div>4=A3=A9driver=B6=CB=CA=FD=BE=DD=D2=E7=B3=F6</d=
iv><div>=B1=A8=B4=ED=A3=BA</div><div>Job aborted due to stage fai=
lure: Total size of serialized results of 334502 tasks (1024.0 MB=
) is bigger than spark.driver.maxResultSize (1024.0 MB)</div><div=
>=B4=A6=C0=ED=A3=BA=B6=D4=D3=DAcollect=BA=CD=D2=BB=D0=A9=B2=D9=D7=
=F7=A3=ACdriver=BB=E1=BD=D3=CA=D5=B8=F7task=D6=B4=D0=D0=BA=F3=B5=C4=
=CA=FD=BE=DD=A3=ACspark.driver.maxResultSize=B2=CE=CA=FD=BF=D8=D6=
=C6=BD=D3=CA=D5=CA=FD=BE=DD=B4=F3=D0=A1=A3=AC=BD=A8=D2=E9=CF=C8=BC=
=EC=B2=E9=B4=FA=C2=EB=A3=AC=B1=DC=C3=E2=BB=F2=BC=F5=C9=D9take=A3=AC=
collect=B2=D9=D7=F7=A3=AC=C8=E7=B9=FB=B2=BB=B3=C9=B9=A6=D4=D9=BF=BC=
=C2=C7=D4=F6=B4=F3=B8=C3=B2=CE=CA=FD=A1=A3</div><div><br></div><d=
iv>5=A3=A9container=C4=DA=B4=E6=B2=BB=D7=E3=B1=BBkill</div><div>=B1=
=A8=B4=ED=A3=BA</div><div>Job aborted due to stage failure Execut=
orLostFailure (executor 2101 exited caused by one of the running=20=
tasks) Reason: Container marked as failed: container_149181433201=
6_46280_01_009179 on host</div><div>=B4=A6=C0=ED=A3=BA1=A1=A2=D4=F6=
=B4=F3=B7=D6=C7=F8=CA=FD=A3=AC=CA=B9=D3=C3 set spark.sql.shuffle.=
partitions=3D1000(=BB=F2=B8=FC=B4=F3)</div><div>2=A1=A2=B5=F7=D5=FB=
=B4=FA=C2=EB=A3=AC=BC=F5=C9=D9=CA=FD=BE=DD=B6=C1=C8=A1=C1=BF</div=
><div><br></div><div>5=A3=A9=B5=A5=B8=F6=B7=D6=C7=F8=CA=FD=BE=DD=BF=
=D5=BC=E4=B3=AC=B9=FD2G</div><div>=B1=A8=B4=ED=A3=BA</div><div>ja=
va.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE=20=
at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:828) at or=
g.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskSt=
ore.scala:103) at org.apache.spark.storage.DiskStore$$anonfun$get=
Bytes$2.apply(DiskStore.scala:91) at org.apache.spark.util.Utils$=
.tryWithSafeFinally(Utils.scala:1307) at org.apache.spark.storage=
.DiskStore.getBytes(DiskStore.scala:105) at org.apache.spark.stor=
age.BlockManager.org$apache$spark$storage$BlockManager$$doGetLoca=
lBytes(BlockManager.scala:496) at org.apache.spark.storage.BlockM=
anager$$anonfun$getLocalBytes$2.apply(BlockManager.scala:474) at=20=
org.apache.spark.storage.BlockManager$$anonfun$getLocalBytes$2.ap=
ply(BlockManager.scala:474) at scala.Option.map(Option.scala:146)=
</div><div>=B4=A6=C0=ED=A3=BA=B8=C3=CE=CA=CC=E2=CA=C7=B7=D6=C7=F8=
=CA=FD=BE=DD=B4=E6=B4=A2=B5=C4=CA=B1=BA=F2=B3=F6=CF=D6=B1=A8=B4=ED=
=A3=AC=D2=F2=CE=AA=B5=A5=B8=F6=B7=D6=C7=F8=C9=CF=CF=DE=CA=C72G=A3=
=AC=B3=AC=B9=FD=B8=C3=CF=DE=D6=C6=D4=F2=B1=A8=B4=ED=A3=AC=BD=E2=BE=
=F6=B7=BD=B7=A8=CA=C7=B5=F7=B4=F3=B7=D6=C7=F8=A3=AC=CA=B9=D3=C3re=
partition=BB=F2=B6=D4=BA=AC=D3=D0shuffle=CB=E3=D7=D3=D6=B8=B6=A8=D2=
=BB=B8=F6=B4=F3=B7=D6=C7=F8=BC=B4=BF=C9=A1=A3</div><div><br></div=
><div>=B2=BB=BD=F6=C8=E7=B4=CB=A3=ACshuffle =B9=FD=B3=CCfetch blo=
ck=B5=C4=D7=EE=B4=F3size=D2=B2=CA=C72G=A1=A3=B4=CB=CD=E2=BB=B9=D3=
=D0=B6=E0=CF=EE=D3=EB2G=D3=D0=B9=D8=B5=C4limitation=D0=E8=D2=AA=D7=
=A2=D2=E2</div><div><br></div><div>=C6=E4=CB=FB=CE=CA=CC=E2</div>=
<div>1=A3=A9=B4=FA=C2=EB=B2=BB=B9=E6=B7=B6</div><div>=B1=A8=B4=ED=
=A3=BA</div><div>org.apache.spark.SparkException: This RDD lacks=20=
a SparkContext. It could happen in the following cases: (1) RDD t=
ransformations and actions are NOT invoked by the driver, but ins=
ide of other transformations; for example, rdd1.map(x =3D&gt; rdd=
2.values.count() * x) is invalid because the values transformatio=
n and count action cannot be performed inside of the rdd1.map tra=
nsformation. For more information, see SPARK-5063.</div><div>=B4=A6=
=C0=ED=A3=BA=D5=E2=B8=F6=B1=A8=B4=ED=CA=C7=D2=F2=CE=AARDD=B5=C4tr=
ansformation=D6=D0=C7=B6=CC=D7transformation=BB=F2action=A3=AC=B5=
=BC=D6=C2=BC=C6=CB=E3=CA=A7=B0=DC=A3=AC=BF=C9=D2=D4=CF=C8=B4=D3=B1=
=A8=B4=ED=C4=C7=D2=BB=D0=D0=D5=D2=B5=BD=C7=B6=CC=D7=B5=C4trans=BB=
=F2action=B2=D9=D7=F7=A3=AC=B0=D1=D5=E2=B8=F6=B2=D9=D7=F7=C4=C3=B3=
=F6=C0=B4=D4=CB=CB=E3=A1=A3</div><div><br></div><div>2=A3=A9=B4=C5=
=C5=CC=C1=D9=CA=B1=CE=C4=BC=FE=BF=D5=BC=E4=B2=BB=D7=E3</div><div>=
=B1=A8=B4=ED=A3=BA</div><div>java.io.IOException: No space left o=
n device</div><div>=B4=A6=C0=ED=A3=BA=D4=DAshuffle=B9=FD=B3=CC=D6=
=D0=A3=AC=D6=D0=BC=E4=CE=C4=BC=FE=B6=BC=B7=C5=D4=DA/tmp=C4=BF=C2=BC=
=A3=AC=B5=B1shuffle=CE=C4=BC=FE=B4=EF=B5=BD=B4=C5=C5=CC=BF=D5=BC=E4=
=C9=CF=CF=DE=A3=AC=BE=CD=B1=A8=B4=ED=A1=A3=BD=E2=BE=F6=B7=BD=B7=A8=
=BF=C9=D2=D4=D4=F6=B4=F3executor=B8=F6=CA=FD=A3=AC=B7=D6=B5=A3=D1=
=B9=C1=A6=A3=AC=C8=E7=B9=FB=C8=D4=B2=BB=BF=C9=D2=D4=B5=C4=BB=B0=BE=
=CD=C1=AA=CF=B5=C6=BD=CC=A8=CD=AC=D1=A7=C5=E4=D6=C3spark-default.=
conf=D6=D0=C9=E8=D6=C3spark.local.dir=A3=A8=C4=AC=C8=CF=CA=C7/tmp=
=A3=A9=CE=AA=B4=C5=C5=CC=BF=D5=BC=E4=D7=E3=B9=BB=B5=C4=C4=BF=C2=BC=
=BC=B4=BF=C9=BD=E2=BE=F6=A1=A3=D4=DAyarn=C4=A3=CA=BD=D4=F2=C5=E4=D6=
=C3LOCAL_DIRS=A1=A3</div><div><br></div><div>3=A3=A9=CE=C4=BC=FE=C3=
=BB=D3=D0=B7=C3=CE=CA=C8=A8=CF=DE</div><div>=B1=A8=B4=ED=A3=BA</d=
iv><div>Caused by: org.apache.hadoop.ipc.RemoteException(org.apac=
he.hadoop.security.AccessControlException): Permission denied: us=
er=3Ddm, access=3DEXECUTE, inode=3D"/user/hadoop/.sparkStaging/ap=
plication_1480755301936_1884":hadoop:supergroup:drwx------</div><=
div>=B4=A6=C0=ED=A3=BA=B2=E9=BF=B4=D5=E2=B8=F6job=CA=C7=CA=B2=C3=B4=
=D3=C3=BB=A7=D6=B4=D0=D0=A3=AC=D2=AA=C8=B7=B6=A8=C8=CE=CE=F1=D6=B4=
=D0=D0=B5=C4=C8=A8=CF=DE=A3=AC=D2=BB=B0=E3=CA=C7=CA=B9=D3=C3=C6=E4=
=CB=FB=D7=E9=BC=FE=B5=F7=D3=C3=A3=AC=B5=BC=D6=C2=D6=B4=D0=D0=D3=C3=
=BB=A7=B1=E4=BB=AF=A3=AC=B5=BC=D6=C2=C3=BB=D3=D0=CE=C4=BC=FE=C8=A8=
=CF=DE=A1=A3</div><div><br></div><div>4=A3=A9yarn cluster=C4=A3=CA=
=BD=CA=B9=D3=C3SQL=D5=D2=B2=BB=B5=BD=B1=ED</div><div>=B1=A8=B4=ED=
=A3=BA</div><div>org.apache.spark.sql.AnalysisException: Table or=
 view not found: at org.apache.spark.sql.catalyst.analysis.packag=
e$AnalysisErrorAt.failAnalysis(package.scala:42) at org.apache.sp=
ark.sql.catalyst.analysis.Analyzer$ResolveRelations$.getTable(Ana=
lyzer.scala:306)</div><div>=B4=A6=C0=ED=A3=BA =D4=DA=CC=E1=BD=BB=B4=
=FA=C2=EB=B2=CE=CA=FD=D6=D0=D4=F6=BC=D3 --files ***/hive-site.xml=
=A3=AC=B2=CE=CA=FD=A3=AC=B1=ED=CA=BE=CC=E1=BD=BB=B4=FA=C2=EB=CA=B1=
=CC=E1=BD=BBhive=CF=E0=B9=D8=C5=E4=D6=C3=D0=C5=CF=A2=A1=A3</div><=
div><br></div><div>5) =B2=CE=CA=FD=CC=E1=BD=BB=CB=B3=D0=F2=B2=BB=B5=
=B1=A3=AC=B5=BC=D6=C2job=B2=BB=C4=DC=CC=E1=BD=BB=B5=BDyarn</div><=
div>=D3=D0=CD=AC=D1=A7submit=C8=CE=CE=F1=B2=CE=CA=FD=CB=B3=D0=F2=B2=
=BB=B5=B1=A3=AC=B5=BC=D6=C2=B2=CE=CA=FD=C3=BB=D3=D0=B4=AB=B5=DD=B3=
=C9=B9=A6=A3=AC=D2=BB=B0=E3=A8Cclass=B2=CE=CA=FD=B7=C5=BA=F3=C3=E6=
=A3=AC=A8Cmaster --conf=D6=AE=C0=E0=B2=CE=CA=FD=D4=DA=C7=B0=C3=E6=
</div><div><br></div><div>6) =CF=B5=CD=B3=B4=E6=D4=DA=B6=E0=B0=E6=
=B1=BEpython=C7=E9=BF=F6=CF=C2=D6=B4=D0=D0bin/pyspark=B1=A8=B4=ED=
</div><div>=B1=A8=B4=ED=A3=BA</div><div>`pyenv: python2.7: comman=
d not found</div><div><br></div><div>The python2.7' command exist=
s in these Python versions: 2.7.7 2.7.8</div><div>=B4=A6=C0=ED=A3=
=BA=CA=D6=B6=AF=D6=B8=B6=A8=CA=B9=D3=C3=B5=C4python=B0=E6=B1=BE=A3=
=AC=C8=E7=D6=B4=D0=D0: pyenv shell 2.7.8</div><div><br></div><div=
>7) jdbc=C1=AC=BD=D3hiveserver2=B3=F6=B4=ED</div><div>=B1=A8=B4=ED=
=A3=BA</div><div>ExecuteStatement failed: out of sequence respons=
e =BB=F2=D5=DFRead a negative frame size (-2147418110)!</div><div=
>=B4=A6=C0=ED=B7=BD=B7=A8=A3=BA=B2=CE=BF=BCHIVE-10410=B5=C4patch<=
/div><div><br></div><div>8=A3=A9=CA=B9=D3=C3spark=BC=AF=C8=BA=C4=A3=
=CA=BD=A3=AC=B1=A8=B1=ED=D5=D2=B2=BB=B5=BD(=D3=C3=BB=A7=B4=ED=CE=BB=
=A3=AC=B5=BC=D6=C2=C8=A8=CF=DE=B1=A8=B4=ED)</div><div>=B1=A8=B4=ED=
=A3=BA</div><div>pyspark.sql.utils.AnalysisException: u'Table or=20=
view not found:online.ml_molive_user_anchor_attr; line 1 pos 33'<=
/div><div>=B4=A6=C0=ED=B7=BD=B7=A8=A3=BA=A8Cfiles /opt/spark2/con=
f/hive-site.xml</div><div><br></div><div>9) =CA=B9=D3=C3spark sql=
=B2=E9=D1=AF=B1=A8=B4=ED=CE=C4=BC=FE=D5=D2=B2=BB=B5=BD</div><div>=
=B1=A8=B4=ED=A3=BA</div><div>java.io.IOException not a file: hdfs=
:// **** java.sql.SQLException</div><div>=B4=A6=C0=ED=A3=BA=C9=E8=
=D6=C3=B2=CE=CA=FD=BC=B4=BF=C9=A3=ACSET mapred.input.dir.recursiv=
e=3Dtrue; SET hive.mapred.supports.subdirectories=3Dtrue;</div><d=
iv><br></div><div>10) =D5=CB=BB=A7=B2=F0=B7=D6=A3=AC=B5=BC=D6=C2=D6=
=B4=D0=D0spark sql=C3=BB=C8=A8=CF=DE</div><div>=B1=A8=B4=ED=A3=BA=
</div><div>py4j.protocol.Py4JJavaError: An error occurred while c=
alling o205.sql. : java.lang.RuntimeException: java.lang.RuntimeE=
xception: java.io.IOException: Permission denied ....... Caused b=
y: java.io.IOException: Permission denied at java.io.UnixFileSyst=
em.createFileExclusively(Native Method) at java.io.File.createNew=
File(File.java:1006) at java.io.File.createTempFile(File.java:198=
9) at org.apache.hadoop.hive.ql.session.SessionState.createTempFi=
le(SessionState.java:818) at org.apache.hadoop.hive.ql.session.Se=
ssionState.start(SessionState.java:513)</div><div>=BD=E2=BE=F6=B7=
=BD=B7=A8=A3=BA=B2=E9=D1=AF=B5=C3=D6=AA=CA=C7=B2=CE=CA=FDhive.exe=
c.local.scratchdir=B6=D4=D3=A6=B5=C4=C2=B7=BE=B6=C3=BB=D3=D0=C8=A8=
=CF=DE=A3=AC=CB=A2=C8=A8=CF=DE=BA=F3=BD=E2=BE=F6=A1=A3</div><div>=
<br></div><div>11) Container marked as failed</div><div>=CE=CA=CC=
=E2=A3=BA</div><div><br></div><div>scheduler.TaskSetManager: Lost=
 task 53.0 in stage 2.2 (TID 440, bigdata38.webmedia.int): Execut=
orLostFailure (executor 9 exited caused by one of the running tas=
ks) Reason: Container marked as failed: container_e50_14903379805=
12_0006_01_000010 on host: bigdata38.webmedia.int. Exit status: 1=
43. Diagnostics: Container killed on request. Exit code is 143</d=
iv><div><br></div><div>ERROR CoarseGrainedExecutorBackend: RECEIV=
ED SIGNAL TERM</div><div><br></div><div>org.apache.spark.rpc.RpcT=
imeoutException: Futures timed out after [20 seconds]. This timeo=
ut is controlled by spark.executor.heartbeatInterval</div><div>1<=
/div><div>2</div><div>3</div><div>4</div><div>5</div><div>=A3=A8=D2=
=D4=C9=CF=CA=C7=B7=D6=CE=F6=B2=BB=CD=AC=BD=F8=B3=CC=C8=D5=D6=BE=BB=
=E3=D7=DC=B5=C3=B5=BD=A3=A9</div><div><br></div><div>=CE=CA=CC=E2=
=D4=AD=D2=F2=A3=BA=CB=E4=C8=BB=D2=D4=C9=CF=B1=A8=B4=ED=B2=BB=C4=DC=
=D6=B1=BD=D3=BF=B4=B3=F6=D4=AD=D2=F2=A3=AC=B5=AB=B4=F3=B8=C5=C2=CA=
=D3=EB=C4=DA=B4=E6=CF=E0=B9=D8=A3=AC=D2=F2=CE=AA=D7=F7=D2=B5=C4=DA=
=B4=E6=B2=BB=D7=E3=A3=AC=B5=BC=D6=C2GC=A3=ACGC=BF=C9=C4=DC=B5=BC=D6=
=C2executor=D3=EBAM=CD=A8=D0=C5=B3=AC=CA=B1=A3=AC=B9=CAAM=C8=CF=CE=
=AAexecutor=B9=D2=C1=CB=A3=AC=BB=E1=B7=A2=CD=A3=D6=B9=B5=C4signal=
=A1=A3</div><div>=BD=E2=BE=F6=A3=BA1=A1=A2=D4=F6=BC=D3=D3=B2=BC=FE=
=D7=CA=D4=B4 2=A1=A2=D4=F6=B4=F3=D7=F7=D2=B5=B2=A2=B7=A2=B6=C8=A3=
=AC=BC=D3=B4=F3executor=CD=A8=D0=C5=B3=AC=CA=B1=CA=B1=BC=E4spark.=
executor.heartbeatInterval</div><div><br></div><div>12=A3=A9java.=
lang.NoSuchMethodError: javax.ws.rs.core.Application.getPropertie=
s()Ljava/util/Map;</div><div>=B8=B4=CF=D6=B9=FD=B3=CC=A3=BAspark=20=
2.2.1 =D4=CB=D0=D0SparkThriftserver=A3=AC=B5=E3=BB=F7=B2=E9=BF=B4=
executor=BA=F3=C3=BB=D3=D0=CA=FD=BE=DD=D0=C5=CF=A2=A1=A3</div><di=
v>=B1=A8=B4=ED=A3=BA</div><div><br></div><div>=B5=DA=D2=BB=B4=CE=B5=
=E3=BB=F7=B2=E9=BF=B4exevutor=D2=B3=C3=E6=B1=A8=C8=E7=CF=C2=B4=ED=
=CE=F3=A3=BA</div><div>java.lang.NoSuchMethodError: javax.ws.rs.c=
ore.Application.getProperties()Ljava/util/Map;</div><div>&nbsp; &=
nbsp; &nbsp; &nbsp; at org.glassfish.jersey.server.ApplicationHan=
dler.&lt;init&gt;(ApplicationHandler.java:331)</div><div>&nbsp; &=
nbsp; &nbsp; &nbsp; at org.glassfish.jersey.servlet.WebComponent.=
&lt;init&gt;(WebComponent.java:392)</div><div>&nbsp; &nbsp; &nbsp=
; &nbsp; at org.glassfish.jersey.servlet.ServletContainer.init(Se=
rvletContainer.java:177)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at=
 org.glassfish.jersey.servlet.ServletContainer.init(ServletContai=
ner.java:369)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at javax.serv=
let.GenericServlet.init(GenericServlet.java:244)</div><div>&nbsp;=
 &nbsp; &nbsp; &nbsp; at org.spark_project.jetty.servlet.ServletH=
older.initServlet(ServletHolder.java:640)</div><div>&nbsp; &nbsp;=
 &nbsp; &nbsp; at org.spark_project.jetty.servlet.ServletHolder.g=
etServlet(ServletHolder.java:496)</div><div>&nbsp; &nbsp; &nbsp;=20=
&nbsp; at org.spark_project.jetty.servlet.ServletHolder.ensureIns=
tance(ServletHolder.java:788)</div><div>&nbsp; &nbsp; &nbsp; &nbs=
p; at org.spark_project.jetty.servlet.ServletHolder.prepare(Servl=
etHolder.java:773)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.s=
park_project.jetty.servlet.ServletHandler.doHandle(ServletHandler=
.java:578)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_pro=
ject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.=
java:1180)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_pro=
ject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511=
)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_project.jett=
y.server.handler.ContextHandler.doScope(ContextHandler.java:1112)=
</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_project.jetty=
.server.handler.ScopedHandler.handle(ScopedHandler.java:141)</div=
><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_project.jetty.serv=
er.handler.gzip.GzipHandler.handle(GzipHandler.java:461)</div><di=
v>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_project.jetty.server.h=
andler.ContextHandlerCollection.handle(ContextHandlerCollection.j=
ava:213)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_proje=
ct.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java=
:134)</div><div>&nbsp; &nbsp; &nbsp; &nbsp; at org.spark_project.=
jetty.server.Server.handle(Server.java:524)</div><div>&nbsp; &nbs=
p; &nbsp; &nbsp; .....</div><div>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp=
;</div><div>&nbsp; =B5=DA=B6=FE=B4=CE=B5=E3=BB=F7=B2=E9=BF=B4exec=
utor=B5=C4tab &nbsp;</div><div>17/12/04 12:48:36 WARN ServletHand=
ler: /api/v1/applications/application_1511942712793_0065/allexecu=
tors</div><div>java.lang.NullPointerException</div><div>&nbsp;at=20=
org.glassfish.jersey.servlet.ServletContainer.service(ServletCont=
ainer.java:388)</div><div>&nbsp;at org.glassfish.jersey.servlet.S=
ervletContainer.service(ServletContainer.java:341)</div><div>&nbs=
p;at org.glassfish.jersey.servlet.ServletContainer.service(Servle=
tContainer.java:228)</div><div>&nbsp;at org.spark_project.jetty.s=
ervlet.ServletHolder.handle(ServletHolder.java:845)</div><div>&nb=
sp;at org.spark_project.jetty.servlet.ServletHandlerCachedChain.d=
oFilter(ServletHandler.java:1689)</div><div>&nbsp;at org.apache.h=
adoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilte=
r.java:159)</div><div>&nbsp;at org.spark_project.jetty.servlet.Se=
rvletHandlerCachedChain.doFilter(ServletHandler.java:1676)</div><=
div>&nbsp;at org.spark_project.jetty.servlet.ServletHandler.doHan=
dle(ServletHandler.java:581)</div><div>&nbsp;.........</div><div>=
1</div><div>2</div><div>3</div><div>4</div><div>5</div><div>6</di=
v><div>7</div><div>8</div><div>9</div><div>10</div><div>11</div><=
div>12</div><div>13</div><div>14</div><div>15</div><div>16</div><=
div>17</div><div>18</div><div>19</div><div>20</div><div>21</div><=
div>22</div><div>23</div><div>24</div><div>25</div><div>26</div><=
div>27</div><div>28</div><div>29</div><div>30</div><div>31</div><=
div>32</div><div>33</div><div>34</div><div>**=BD=E2=BE=F6=B7=BD=B7=
=A8=A3=BA**=B1=A8=B4=ED=CA=C7=D2=F2=CE=AA Application#getProperti=
es() =B7=BD=B7=A8=CA=F4=D3=DAJAX-RS 2=D0=AD=D2=E9=A3=A8javax.ws.r=
s-api-2.0.1.jar=A3=A9=A3=AC=B6=F8=B2=BB=CA=C7JAX-RS 1=A3=A8jsr311=
-api.jar=A3=A9=A3=AC=CB=F9=D2=D4=CF=EE=C4=BF=D6=D0=BF=C9=C4=DCjar=
=B0=FC=B0=E6=B1=BE=B3=E5=CD=BB=B5=BC=D6=C2=A1=A3</div><div>=D3=DA=
=CA=C7=B2=E9=D5=D2$SPARK_HOME/jars=CF=C2=B5=C4=B0=FC=A3=AC=B0=D1j=
sr311-api-1.1.1.jar=C9=BE=B5=F4=BE=CD=BD=E2=BE=F6=D2=D4=C9=CF=CE=CA=
=CC=E2=A1=A3</div><div><br></div><div>(=D2=D4=C9=CF=BE=F9=CE=AA=B9=
=A4=D7=F7=D6=D0=D3=F6=BC=FB=B9=FD=B5=C4=CE=CA=CC=E2=A3=AC=B7=D6=CF=
=ED=B3=F6=C0=B4=A3=AC=BA=F3=C3=E6=B3=D6=D0=F8=B8=FC=D0=C2=A1=AD)<=
/div><div><br></div><div>=B2=CE=BF=BC=A3=BA</div><div>spark 2.x y=
arn errors and some solution</div><div><br></div><div>13=A3=A9 sp=
ark=D2=F2=CE=AA=CA=E4=C8=EB=D0=A1=CE=C4=BC=FE=B9=FD=B6=E0=B5=BC=D6=
=C2task=CA=FD=C4=BF=BA=DC=B4=F3=A3=AC=D7=F7=D2=B5=D0=A7=C2=CA=CF=C2=
=BD=B5=A1=A3</div><div><br></div><div>=CA=B9=D3=C3 newAPIHadoopFi=
le API=CD=EA=B3=C9=CA=FD=BE=DD=CA=E4=C8=EB=A3=AC=D1=A1=D4=F1org.a=
pache.hadoop.mapreduce.lib.input.CombineTextInputFormat=C0=E0=BF=C9=
=D2=D4=BD=AB=B6=E0=B8=F6=D0=A1=CE=C4=BC=FE=BA=CF=B2=A2=C9=FA=B3=C9=
=D2=BB=B8=F6Split=A3=A8=D2=BB=B8=F6split=B6=D4=D3=A6=D2=BB=B8=F6p=
atition=A3=AC=D2=BB=B8=F6partition=B6=D4=D3=A6=D2=BB=B8=F6task=A3=
=A9=A3=AC=B4=D3=B6=F8=BC=F5=D0=A1task=CA=FD=C4=BF</div><div><br><=
/div><div>=B2=CE=BF=BC=A3=BAspark=CA=E4=C8=EB=D0=A1=CE=C4=BC=FE=BA=
=CF=B2=A2</div><div><br></div><div>14)Spark =B6=C1=C8=A1Hbase =D3=
=B3=C9=E4=B5=BDHive=D6=D0=B5=C4=CD=E2=B2=BF=B1=ED=B1=A8</div><div=
>=B1=A8=B4=ED=A3=BA</div><div><br></div><div>1=A3=A9java.lang.NoS=
uchMethodError: org.apache.hadoop.hive.serde2.lazy.LazySim</div><=
div>java.lang.NoSuchMethodError:&nbsp;</div><div>2=A3=A9org.apach=
e.hadoop.hive.serde2.lazy.LazySimpleSerDe.initSerdeParams(Lorg/ap=
ache/hadoop/conf/Configuration;Ljava/util/Properties;Ljava/lang/S=
tring;)Lorg/apache/hadoop/hive/serde2/lazy/LazySimpleSerDe$SerDeP=
arameters;</div><div>1</div><div>2</div><div>3</div><div>spark=D6=
=B4=D0=D0hive=D2=FD=C8=EB=B5=C4hbase=CD=E2=B2=BF=B1=ED=A3=AC=D0=E8=
=D2=AA=D4=DAspark=B5=C4jars=D6=D0=BC=D3=C8=EBhbase=CF=E0=B9=D8=B5=
=C4=B0=FC=A3=AC=B3=FD=C1=CB=B0=FC=BA=AChbase=B5=C4=B0=FC=A3=AC=BB=
=B9=D0=E8=D2=AAhtrace-core-2.04.jar=A1=A2hive-serde-**.jar</div><=
div><br></div><div>=BC=D3=C8=EB=BD=F8=C8=EB=BA=F3=BB=B9=D2=AA=D2=FD=
=C8=EBhbase-site.xml=B5=BD$SPARK_HOME/conf=D6=D0</div><div>=B2=CE=
=BF=BC=A3=BAspark sql=B6=C1hbase=CA=FD=BE=DD</div><div><br></div>=
<div>=D0=C2=CE=C4=D5=C2=BB=E1=CD=AC=B2=BD=B5=BD=B9=AB=D6=DA=BA=C5=
=A3=AC=B9=D8=D7=A2=B9=AB=D6=DA=BA=C5=A3=AC=BD=BB=C1=F7=B8=FC=B7=BD=
=B1=E3?=A3=BA</div><div><br></div><div>=A1=AA=A1=AA=A1=AA=A1=AA=A1=
=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=AA=A1=
=AA</div><div>=B0=E6=C8=A8=C9=F9=C3=F7=A3=BA=B1=BE=CE=C4=CE=AACSD=
N=B2=A9=D6=F7=A1=B8xwc35047=A1=B9=B5=C4=D4=AD=B4=B4=CE=C4=D5=C2=A3=
=AC=D7=F1=D1=AD CC 4.0 BY-SA =B0=E6=C8=A8=D0=AD=D2=E9=A3=AC=D7=AA=
=D4=D8=C7=EB=B8=BD=C9=CF=D4=AD=CE=C4=B3=F6=B4=A6=C1=B4=BD=D3=BC=B0=
=B1=BE=C9=F9=C3=F7=A1=A3</div><div>=D4=AD=CE=C4=C1=B4=BD=D3=A3=BA=
https://blog.csdn.net/xwc35047/article/details/53933265</div></bo=
dy></html>=0A=0A=0A=0A=0A=0A=0A=0A

------=_Next_Part_0000428218.495--

------=_Next_Part_0001284654.531--

